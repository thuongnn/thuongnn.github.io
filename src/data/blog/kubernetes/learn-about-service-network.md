---
author: thuongnn
pubDatetime: 2021-11-28T01:29:35Z
modDatetime: 2025-07-13T06:35:03Z
title: TÃ¬m hiá»ƒu vá» Service network
draft: false
isPinned: true
tags:
  - Kubernetes
  - Networking
description: TÃ¬m hiá»ƒu vá» network trong Kubernetes Service.
ogImage: https://github.com/user-attachments/assets/901f1427-bd81-495f-899b-1125d2432917
---

Trong pháº§n Pod network chÃºng ta Ä‘á»u biáº¿t ráº±ng Pod resource lÃ  Ä‘Æ¡n vá»‹ nhá» nháº¥t sáº½ cÃ³ chá»©a á»©ng dá»¥ng bÃªn trong nÃ³ khi triá»ƒn khai vÃ  loáº¡i resource nÃ y khÃ¡ lÃ  linh hoáº¡t (cÃ³ thá»ƒ scale up, scale down, stop, re-created, re-allocated,â€¦)

Bá»Ÿi sá»± linh hoáº¡t nÃ y nÃªn khÃ´ng cÃ³ gÃ¬ lÃ  cháº¯c cháº¯n Ä‘á»‘i vá»›i IP address cá»§a má»™t Pod, IP address cÃ³ thá»ƒ liÃªn tá»¥c bá»‹ thay Ä‘á»•i trong nhiá»u trÆ°á»ng há»£p â†’ **Váº­y lÃ m sao Ä‘á»ƒ connect giá»¯a 02 Pod vá»›i nhau?**

Láº¡i quay vá» váº¥n Ä‘á» cÅ© (khi cÃ³ nhiá»u replicas cá»§a má»™t service trong Docker Swarm), chÃºng ta láº¡i nghÄ© Ä‘áº¿n cáº§n pháº£i cÃ³ má»™t proxy nhÆ° reverse-proxy/load balancer:

- Client sáº½ káº¿t ná»‘i Ä‘áº¿n proxy vÃ  proxy Ä‘Ã³ Ä‘áº£m nhiá»‡m nhiá»‡m vá»¥ maintain danh sÃ¡ch cÃ¡c healthy servers mÃ  client muá»‘n káº¿t ná»‘i tá»›i.
- Proxy nháº­n biáº¿t cÃ¡c IP address cá»§a Pod cÃ²n sá»‘ng hay Ä‘Ã£ cháº¿t, bá»• sung thÃªm hay loáº¡i bá» bá»›t Pod (replicas) â†’ Tá»« Ä‘Ã¢y client chá»‰ cáº§n káº¿t ná»‘i Ä‘áº¿n IP address cá»§a proxy thÃ´i.

![](https://github.com/user-attachments/assets/3670a594-98f9-4e60-bd6d-5d9559ad2759)

Kubernetes Ä‘Ã£ thiáº¿t káº¿ má»™t resource tÆ°Æ¡ng tá»± nhÆ° thÃ nh pháº§n proxy Ä‘Ã£ nÃ³i á»Ÿ trÃªn gá»i lÃ  Service, Service resource cÃ³ Ä‘áº·c Ä‘iá»ƒm nhÆ° sau:

- it must itself be durable and resistant to failure.
- it must have a list of servers it can forward to.
- it must have some way of knowing if a particular server is healthy and able to respond to requests.

## Table of contents

## Váº­y Kubernetes Service hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o?

Äá»ƒ tÃ¬m hiá»ƒu cÃ¡ch mÃ  Service hoáº¡t Ä‘á»™ng, chÃºng ta sáº½ táº¡o má»™t Deployment resource nhÆ° sau:

```yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: service-test
spec:
  replicas: 2
  selector:
    matchLabels:
      app: service_test_pod
  template:
    metadata:
      labels:
        app: service_test_pod
    spec:
      containers:
        - name: simple-http
          image: python:2.7
          imagePullPolicy: IfNotPresent
          command: ["/bin/bash"]
          args:
            [
              "-c",
              'echo "<p>Hello from $(hostname)</p>" > index.html; python -m SimpleHTTPServer 8080',
            ]
          ports:
            - name: http
              containerPort: 8080
```

Deployment sáº½ triá»ƒn khai 02 simple http server Pods vÃ  listen á»Ÿ port 8080, kiá»ƒm tra Ä‘á»‹a chá»‰ IP cá»§a 02 Pods:

```shell
kubectl get pods --selector=app=service_test_pod -o jsonpath='{.items[*].status.podIP}'
```

Kiá»ƒm tra káº¿t ná»‘i tá»›i má»™t trong 02 Pods trÃªn báº±ng cÃ¡ch cháº¡y má»™t client Pod nhÆ° sau:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: service-test-client1
spec:
  restartPolicy: Never
  containers:
    - name: test-client1
      image: alpine
      command: ["/bin/sh"]
      args: ["-c", "echo 'GET / HTTP/1.1\\r\\n\\r\\n' | nc 10.0.2.2 8080"]
```

Client Pod á»Ÿ trÃªn sáº½ táº¡o má»™t káº¿t ná»‘i tá»›i Ä‘á»‹a chá»‰ IP `10.0.2.2` (cÃ³ thá»ƒ thay tháº¿ IP address nÃ y báº±ng Ä‘á»‹a chá»‰ IP cá»§a má»™t trong 02 Pod á»Ÿ trÃªn). Xem káº¿t quáº£ cháº¡y cá»§a client Pod Ä‘Ã£ triá»ƒn khai báº±ng command kubectl logs `service-test-client1`.

ChÃºng ta tháº¥y ráº±ng viá»‡c káº¿t ná»‘i thÃ´ng qua IP address cá»§a Pod khÃ¡ lÃ  khÃ³ khÄƒn:

- Cáº§n pháº£i láº¥y thá»§ cÃ´ng IP address cá»§a cÃ¡c Pod trong Deployment resource.
- IP address sáº½ bá»‹ thay Ä‘á»•i vÃ  láº¥y thá»§ cÃ´ng láº¡i láº§n ná»¯a trong cÃ¡c trÆ°á»ng há»£p Pod (stop, scale up, scale down,â€¦)
- KhÃ´ng táº­n dá»¥ng Ä‘Æ°á»£c háº¿t hiá»‡u nÄƒng khi cÃ¡c káº¿t ná»‘i tá»« client Pod khÃ´ng Ä‘Æ°á»£c chia Ä‘á»u ra cÃ¡c Pod trong Deployment resource.

Tá»« váº¥n Ä‘á» trÃªn k8s cÃ³ há»— trá»£ chÃºng ta má»™t loáº¡i resource lÃ  Service cÃ³ thá»ƒ giáº£i quyáº¿t Ä‘Æ°á»£c váº¥n Ä‘á» nÃ y, triá»ƒn khai Service nhÆ° sau:

```yaml
kind: Service
apiVersion: v1
metadata:
  name: service-test
spec:
  selector:
    app: service_test_pod
  ports:
    - port: 80
      targetPort: 8080
```

```shell
kubectl get service service-test
```

```text
NAME           CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE
service-test   10.3.241.152   <none>        80/TCP    11s
```

Service resource sáº½ cáº¥u hÃ¬nh má»™t proxy Ä‘á»ƒ forward cÃ¡c request cá»§a client tá»›i danh sÃ¡ch Pod thÃ´ng qua labels Ä‘Ã£ Ä‘Æ°á»£c assign khi khá»Ÿi táº¡o (labels trong Deployment resource).

NhÆ° khai bÃ¡o Service á»Ÿ trÃªn, k8s sáº½ táº¡o má»™t Service cÃ³ tÃªn `service-test` gÃ¡n vá»›i má»™t Ä‘á»‹a chá»‰ IP vÃ  listen port 80. Äiá»u nÃ y cÃ³ nghÄ©a ráº±ng client cÃ³ thá»ƒ káº¿t ná»‘i tá»›i cÃ¡c http server Pods thÃ´ng qua IP address `10.3.241.152` vÃ  port 80:

CÃ³ láº½ chÃºng ta sáº½ khÃ´ng cáº§n pháº£i dÃ¹ng Ä‘áº¿n IP address cá»§a Service, k8s Ä‘Ã£ cung cáº¥p má»™t internal cluster DNS há»— trá»£ resolves IP address cá»§a Service thÃ´ng qua Service name. Thá»­ kiáº¿m tra báº±ng cÃ¡ch káº¿t ná»‘i tá»›i `service-test` nhÆ° sau:

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: service-test-client2
spec:
  restartPolicy: Never
  containers:
    - name: test-client2
      image: alpine
      command: ["/bin/sh"]
      args: ["-c", "echo 'GET / HTTP/1.1\\r\\n\\r\\n' | nc service-test 80"]
```

Kiá»ƒm tra logs cá»§a client Pod nháº­n tháº¥y káº¿t quáº£ tráº£ vá» khÃ´ng khÃ¡c gÃ¬ vá»›i cÃ¡ch truy cáº­p báº±ng IP address. Náº¿u cháº¡y láº¡i nhiá»u láº§n client Pod á»Ÿ trÃªn chÃºng ta sáº½ tháº¥y káº¿t quáº£ tráº£ vá» sáº½ Ä‘Æ°á»£c LB round robin tá»›i 02 http server Pods. Great ğŸ˜‰

## Service Network

Kiáº¿n trÃºc káº¿t ná»‘i giá»¯a client Pod vÃ  server Pod (triá»ƒn khai á»Ÿ trÃªn) Ä‘Æ°á»£c phÃ¡c hoáº¡ láº¡i nhÆ° sau:

![](https://github.com/user-attachments/assets/2877df2d-e429-40f7-8f1b-1d29d29f4d09)

ChÃºng ta cÃ³ dáº£i máº¡ng `10.100.0.0/24` chÃ­nh lÃ  network chá»©a IP address cá»§a cÃ¡c server node trong cá»¥m k8s, cÃ¡c server node sáº½ giao tiáº¿p vá»›i nhau thÃ´ng qua dáº£i máº¡ng nÃ y.

- Äá»‘i vá»›i cá»¥m k8s Ä‘Æ°á»£c triá»ƒn khai trÃªn cÃ¡c dá»‹ch vá»¥ public cloud (AWS, Azure, Google Cloud) thÃ¬ cÃ¡c server node sáº½ giao tiáº¿p vá»›i nhau thÃ´ng qua private network (Ä‘Æ°á»£c táº¡o bá»Ÿi VPC network). CÃ¡c client request sáº½ káº¿t ná»‘i vá»›i cá»¥m thÃ´ng qua public IP address.
- Äá»‘i vá»›i cá»¥m k8s triá»ƒn khai trÃªn cÃ¡c virtual machine, cloud server thÃ´ng thÆ°á»ng thÃ¬ sáº½ káº¿t ná»‘i vá»›i nhau thÃ´ng qua Ä‘Æ°á»ng internet (Ä‘Æ°á»ng ra vÃ o trÃªn chÃ­nh public IP address cá»§a cÃ¡c server node).

Dáº£i máº¡ng `10.0.0.0/14` lÃ  network do k8s táº¡o vÃ  quáº£n lÃ½ riÃªng trÃªn tá»«ng server node (má»—i server node sáº½ cÃ³ lá»›p máº¡ng riÃªng):

- Dáº£i máº¡ng `cbr0` (custom bridge network) tÆ°Æ¡ng tá»± nhÆ° `docker0` (bridge network) váº­y. Chá»‰ khÃ¡c lÃ  nÃ³ Ä‘áº·c biá»‡t hÆ¡n, do k8s quáº£n lÃ½ trÃªn táº¥t cáº£ cÃ¡c server node.
- Má»—i Pod resource sáº½ Ä‘Æ°á»£c assign má»™t IP address trÃªn dáº£i máº¡ng cá»§a `cbr0`.

Báº£ng Routing table thá»±c cháº¥t sáº½ Ä‘Æ°á»£c Ä‘áº·t trÃªn táº¥t cáº£ cÃ¡c host (node) vÃ  Ä‘Æ°á»£c quáº£n lÃ½ bá»Ÿi kube-proxy, khi cÃ³ báº¥t cá»© thÃ´ng tin thay Ä‘á»•i nÃ o thÃ¬ k8s master sáº½ thá»±c hiá»‡n gá»­i Ä‘á»“ng bá»™ xuá»‘ng cho kube-proxy vÃ  nÃ³ sáº½ update rules vÃ o Routing table.

Khi chÃºng ta táº¡o Service resource, thá»±c cháº¥t nÃ³ sáº½ hoáº¡t Ä‘á»™ng nhÆ° sau:

```shell
kubectl describe services service-test
```

```text
Name:                   service-test
Namespace:              default
Labels:                 <none>
Selector:               app=service_test_pod
Type:                   ClusterIP
IP:                     10.3.241.152
Port:                   http    80/TCP
Endpoints:              10.0.1.2:8080,10.0.2.2:8080
Session Affinity:       None
Events:                 <none>
```

![](https://github.com/user-attachments/assets/d5ffe94d-24de-4e6f-a3cd-fc66e270485b)

- Báº£n cháº¥t khi táº¡o Service resource, nÃ³ sáº½ tá»± sinh ra Endpoint resource Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ mapping vá»›i Pod resource nhÆ° hÃ¬nh á»Ÿ trÃªn (mapping vá»›i IP address vÃ  port cá»§a Pod resource). Äá»‹a chá»‰ IP cá»§a Service resource mÃ  client Pod káº¿t ná»‘i tá»›i lÃ  má»™t Ä‘á»‹a chá»‰ IP áº£o Ä‘Æ°á»£c táº¡o vÃ  quáº£n lÃ½ bá»Ÿi `kube-proxy`.
- DNS server cá»§a k8s (chÃ­nh lÃ  `core-dns` container) sáº½ lÆ°u trá»¯ cÃ¡c A record vÃ  thá»±c hiá»‡n resolve Ä‘á»‹a chá»‰ IP cho client Pod. NhÆ° á»Ÿ hÃ¬nh trÃªn thÃ¬ cÃ³ thá»ƒ tháº¥y Ä‘Æ°á»£c DNS server sáº½ resolve domain `service-test` vÃ  tráº£ vá» cho client Pod Ä‘á»‹a chá»‰ IP lÃ  `10.3.241.152`, cÃ¡c gÃ³i tin Ä‘i ra tá»« client Pod sáº½ Ä‘Æ°á»£c set Destination IP lÃ  `10.3.241.152` trong header.

BÃ¢y giá» chÃºng ta sáº½ báº¯t Ä‘áº§u quÃ¡ trÃ¬nh tá»« client Pod khi káº¿t ná»‘i tá»›i server Pod thÃ´ng qua Service resource vá»›i diagram sau Ä‘Ã¢y:
![](https://github.com/user-attachments/assets/901f1427-bd81-495f-899b-1125d2432917)

- CÃ¡c gÃ³i tin Ä‘Æ°á»£c gá»­i tá»« client Pod sáº½ cÃ³ destination IP lÃ  `10.3.241.152` (chÃ­nh lÃ  Ä‘á»‹a chá»‰ IP áº£o cá»§a Service resource, nÃ³ Ä‘Æ°á»£c resolve khi gá»i Ä‘áº¿n `service-test`), nhá»¯ng gÃ³i tin nÃ y sáº½ Ä‘Æ°á»£c forward tá»›i gateway cá»§a card máº¡ng `cbr0` (gateway ip lÃ  `10.0.1.1`) bá»Ÿi vÃ¬ máº¡ng nÃ y khÃ´ng biáº¿t destination IP cá»§a gÃ³i tin.
- CÃ¡c gÃ³i tin Ä‘Ã³ sáº½ Ä‘i ra ngoÃ i tá»›i card máº¡ng `eth0` cá»§a mÃ¡y host, `eth0` network cÅ©ng khÃ´ng biáº¿t gá»­i gÃ³i tin Ä‘i Ä‘Ã¢u vÃ  nÃ³ sáº½ tiáº¿p tá»¥c forward gÃ³i tin tá»›i gateway IP lÃ  `10.100.0.1`. Äiá»ƒm máº¥u chá»‘t chÃ­nh lÃ  á»Ÿ báº£ng Routing table, cÃ¡c gÃ³i tin tá»›i gateway `10.100.0.1` sáº½ Ä‘Æ°á»£c NAT láº¡i packet header vÃ  routing tá»›i node phÃ¹ há»£p.
- Cá»¥ thá»ƒ trong diagram phÃ­a trÃªn, cÃ¡c header cá»§a gÃ³i tin cÃ³ thÃ´ng tin Destination IP vÃ  Destination Port lÃ  `10.3.241.152:80` (virtual IP cá»§a Service resource tá»± sinh vÃ  port do ngÆ°á»i dÃ¹ng thiáº¿t láº­p), routing table sáº½ NAT láº¡i cÃ¡c thÃ´ng tin Destination IP vÃ  Destination Port lÃ  `10.0.2.2:8080` (Ä‘á»‹a chá»‰ IP cá»§a tháº±ng server Pod 2 vÃ  port á»©ng dá»¥ng trong Pod Ä‘Ã³).

## CÃ³ má»™t váº¥n Ä‘á» lÃ  lÃ m sao Ä‘á»ƒ NAT Ä‘Æ°á»£c gÃ³i tin tá»›i Ä‘Ãºng Ä‘á»‹a chá»‰ IP cá»§a server Pod, vÃ  cÃ¡c gÃ³i tin nÃ y Ä‘Æ°á»£c cÃ¢n báº±ng táº£i Ä‘á»u giá»¯a 02 Pod nhÆ° tháº¿ nÃ o?

CÃ¢u tráº£ lá»i Ä‘Ã³ chÃ­nh lÃ  kube-proxy vÃ  network provider, xem diagram chi tiáº¿t dÆ°á»›i Ä‘Ã¢y:

![](https://github.com/user-attachments/assets/882c6c49-1632-44e1-80c2-8e32b822a59b)

**Netfilter** lÃ  má»™t cÃ´ng cá»¥ trong kernel space cho phÃ©p cáº­p nháº­t rules liÃªn quan tá»›i Ä‘á»‹nh tuyáº¿n gÃ³i tin trong linux, cháº¯c háº³n chÃºng ta Ä‘á»u biáº¿t Ä‘áº¿n tháº±ng iptables â€” nÃ³ chÃ­nh lÃ  interface tÆ°Æ¡ng tÃ¡c vá»›i netfilter Ä‘á»ƒ cáº¥u hÃ¬nh firewall (khÃ¡c nhau giá»¯a netfilter vÃ  iptables xem [á»Ÿ Ä‘Ã¢y](https://www.zdnet.com/article/netfilter-and-iptables-stateful-firewalling-for-linux/#:~:text=There%20may%20be%20some%20confusion,classify%20and%20act%20on%20packets.)).

Trong kiáº¿n trÃºc cá»§a k8s thÃ¬ tháº±ng kube-proxy sáº½ tÆ°Æ¡ng tÃ¡c vá»›i **interface network provider** vÃ  tháº±ng **network provider** nÃ y cÃ³ nhiá»‡m vá»¥ tÆ°Æ¡ng tÃ¡c vá»›i netfilter trong kernel space Ä‘á»ƒ cáº­p nháº­t rules Ä‘Æ°á»£c gá»­i tá»« apiserver:

- Khi chÃºng ta táº¡o hay cáº­p nháº­t Pod, Service, Endpoint resource,â€¦ â†’ cÃ¡c routing rules liÃªn quan sáº½ Ä‘Æ°á»£c tá»± Ä‘á»™ng gá»­i vÃ o kube-proxy, kube-proxy sáº½ cÃ³ nhiá»‡m vá»¥ update chÃºng vÃ o network provider.
- CÆ¡ cháº¿ Pod healcheck cÅ©ng váº­y, thÃ´ng tin (tráº¡ng thÃ¡i) cá»§a server Pod sáº½ Ä‘Æ°á»£c kubelet thu tháº­p vÃ  gá»­i vá» apiserver. Náº¿u tráº¡ng thÃ¡i cá»§a Pod bá»‹ thay Ä‘á»•i, apiserver sáº½ tá»± Ä‘á»™ng gá»­i vá» kube-proxy cá»§a cÃ¡c host(node) Ä‘á»ƒ update láº¡i netfilter thÃ´ng qua network provider.
- Network provider chÃ­nh lÃ  thÃ nh pháº§n khi chÃºng ta cÃ i Ä‘áº·t kubernetes (CNI plugins), má»i thÃ´ng tin routing rules trÃªn node sáº½ do tháº±ng nÃ y quáº£n lÃ½ (thÃªm, sá»­a, xoÃ¡)

_Táº¥t cáº£ cÃ¡c routing rules sáº½ Ä‘Æ°á»£c liÃªn tá»¥c cáº­p nháº­t vÃ o Routing table cá»§a netfilter_, viá»‡c forward gÃ³i tin hay cÃ¢n báº±ng táº£i cÃ¡c gÃ³i tin Ä‘á»u do tháº±ng netfilter nÃ y lÃ m háº¿t. CÃ¢n báº±ng táº£i thÃ¬ Ä‘Æ°á»£c thá»±c hiá»‡n báº±ng cÆ¡ cháº¿ IPVS, iptables,â€¦ sáº½ tuá»³ thuá»™c theo tháº±ng network provider Ä‘Æ°á»£c sá»­ dá»¥ng lÃ  gÃ¬.

![Diagram chi tiáº¿t hÆ¡n vá» viá»‡c gÃ³i tin Ä‘Æ°á»£c xá»­ lÃ½ vá»›i netfilter, chi tiáº¿t cÃ³ thá»ƒ xem thÃªm [á»Ÿ Ä‘Ã¢y](https://www.stackrox.com/post/2020/01/kubernetes-networking-demystified/)](https://github.com/user-attachments/assets/7ae96fa0-6d4d-41e6-8833-976de1f2b755)_Diagram chi tiáº¿t hÆ¡n vá» viá»‡c gÃ³i tin Ä‘Æ°á»£c xá»­ lÃ½ vá»›i netfilter, chi tiáº¿t cÃ³ thá»ƒ xem thÃªm [á»Ÿ Ä‘Ã¢y](https://www.stackrox.com/post/2020/01/kubernetes-networking-demystified/)_

**Network provider (CNI plugins)**

- NhÆ° Ä‘Ã£ nÃ³i á»Ÿ trÃªn, táº¥t cáº£ cÃ¡c routing rules cá»§a cá»¥m k8s sáº½ Ä‘Æ°á»£c thÃªm vÃ o Routing table â†’ viá»‡c Routing table sáº½ ngÃ y cÃ ng bá»‹ phÃ¬nh ráº¥t lÃ  to bá»Ÿi vÃ¬ má»™t cá»¥m k8s cÃ³ thá»ƒ cháº¡y Ä‘áº¿n hÃ ng nghÃ¬n tÃ i nguyÃªn (Pod, Service, Endpoint resource,â€¦)
- Bá»Ÿi váº­y chÃºng ta cáº§n pháº£i cÃ³ nhá»¯ng cÆ¡ cháº¿, thuáº­t toÃ¡n sá»­ dá»¥ng Ä‘á»ƒ quáº£n lÃ½ cÃ¡c routing rules trong netfilter má»™t cÃ¡ch hiá»‡u quáº£ nháº¥t. ÄÃ¢y chÃ­nh lÃ  tháº±ng network provider (CNI plugins) chÃºng ta nÃ³i á»Ÿ trÃªn, Ä‘Ã£ cÃ³ ráº¥t nhiá»u cÃ¡c CNI plugins Ä‘Æ°á»£c sá»­ dá»¥ng trong cá»™ng Ä‘á»“ng k8s.
- Nhá»¯ng tháº±ng CNI plugins phá»• biáº¿n nhÆ° fannel, calico, cilium, weave-net,â€¦ sáº½ Ä‘Æ°á»£c lá»±a chá»n cÃ i Ä‘áº·t khi dá»±ng cá»¥m k8s, má»—i tháº±ng plugin nÃ y cÃ³ Æ°u nhÆ°á»£c Ä‘iá»ƒm khÃ¡c nhau â†’ tuá»³ theo nhu cáº§u sá»­ dá»¥ng, chÃºng ta sáº½ chá»n plugin phÃ¹ há»£p nháº¥t.

![Xem chi tiáº¿t so sÃ¡nh giá»¯a cÃ¡c CNI plugins [á»Ÿ Ä‘Ã¢y](https://platform9.com/blog/the-ultimate-guide-to-using-calico-flannel-weave-and-cilium/)](https://github.com/user-attachments/assets/4de5ac6c-1595-46f3-bc4d-eb1ef66473ae)_Xem chi tiáº¿t so sÃ¡nh giá»¯a cÃ¡c CNI plugins [á»Ÿ Ä‘Ã¢y](https://platform9.com/blog/the-ultimate-guide-to-using-calico-flannel-weave-and-cilium/)_

## PhÃ¢n loáº¡i Service resource

### Service CÃ“ proxy

![](https://github.com/user-attachments/assets/6fbcfa15-5dcb-4aa4-974a-76075312a766)

- Äáº·c Ä‘iá»ƒm chung cá»§a loáº¡i Service kÃ¨m proxy (cÃ³ type lÃ  **ClusterIP**, **NodePort**, **LoadBalancer**) lÃ  gom toÃ n bá»™ cÃ¡c Pod vá»›i cÆ¡ cháº¿ selector label qua má»™t Virtual IP chung (nhÆ° Ä‘Ã£ giáº£i thÃ­ch á»Ÿ trÃªn).
- CÃ¡c request gá»i Ä‘áº¿n Service kÃ¨m proxy sáº½ Ä‘Æ°á»£c tá»± Ä‘á»™ng load balacing (round-robin) tá»›i cÃ¡c Pod phÃ­a sau nÃ³, tá»± Ä‘á»™ng discovery khi cÃ¡c Pod (cÃ³ label Ä‘Ã£ Ä‘Äƒng kÃ½ vá»›i Service) Ä‘Æ°á»£c khá»Ÿi cháº¡y hoáº·c dá»«ng.
- Proxy á»Ÿ Ä‘Ã¢y lÃ  cÆ¡ cháº¿ Ä‘Ã£ giáº£i thÃ­ch á»Ÿ phÃ¢n Service resource hoáº¡t Ä‘á»™ng nhÆ° nÃ o? cÃ¡ch mÃ  chÃºng Ä‘Æ°á»£c cÃ¢n báº±ng táº£i, hay cÃ¡ch chÃºng káº¿t ná»‘i vá»›i nhau.

**ClusterIP**

![](https://github.com/user-attachments/assets/c4701fef-447c-4c69-92f4-a2e626755166)

á» vÃ­ dá»¥ trÆ°á»›c chÃºng ta sá»­ dá»¥ng Service vá»›i type máº·c Ä‘á»‹nh lÃ  ClusterIP, loáº¡i Service nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ giao tiáº¿p ná»™i bá»™ trong cá»¥m k8s. VÃ­ dá»¥ nhÆ° client Pod káº¿t ná»‘i tá»›i 02 server Pod thÃ´ng qua Service resource, **ClusterIP** chá»‰ lÃ  má»™t IP áº£o `10.3.241.152` - chá»‰ cÃ³ nhá»¯ng Pod resource cháº¡y bÃªn trong cá»¥m má»›i cÃ³ thá»ƒ káº¿t ná»‘i Ä‘áº¿n ClusterIP nÃ y.

```yaml
apiVersion: v1
kind: Service
metadata:
  name: service-test
spec:
  type: ClusterIP # Chá»‰ táº¡o Virtual IP
  selector:
    app: service_test_pod # Label selector
  ports:
    - protocol: TCP # Protocol
      port: 80 # Port cá»§a Service
      targetPort: 8080 # Port cá»§a Pod
```

**NodePort**

![](https://github.com/user-attachments/assets/35564293-4230-4083-9604-21ca5800b7fd)

_Váº¥n Ä‘á» á»Ÿ Ä‘Ã¢y lÃ  lÃ m sao cho client cÃ³ thá»ƒ káº¿t ná»‘i tá»›i cÃ¡c service Pod trong cá»¥m k8s?_ tá»« Ä‘Ã¢y k8s má»›i cung cáº¥p loáº¡i Service type lÃ  **NodePort**. CÃ¡c client á»Ÿ bÃªn ngoÃ i cá»¥m k8s lÃºc nÃ y cÃ³ thá»ƒ truy cáº­p vÃ o cá»¥m thÃ´ng qua IP address `10.100.0.2`

Khi táº¡o Service resource cÃ³ type lÃ  NodePort, k8s sáº½ tá»± Ä‘á»™ng táº¡o thÃ nh pháº§n ClusterIP (tá»± táº¡o Virtual IP) rá»“i mapping tá»›i má»™t port ngáº«u nhiÃªn (30000~32767) trÃªn táº¥t cáº£ cÃ¡c worker node (port nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c cáº¥u hÃ¬nh fix cá»©ng thÃ´ng qua yaml file).

VÃ­ dá»¥ á»Ÿ hÃ¬nh bÃªn trÃªn, client cÃ³ thá»ƒ truy cáº­p vÃ o Ä‘á»‹a chá»‰ IP `10.100.0.2:30080` hoáº·c `10.100.0.3:30080` (miá»…n sao client cÃ¹ng dáº£i máº¡ng vá»›i cá»¥m k8s). Port **30080** sáº½ Ä‘Æ°á»£c listen trÃªn card eth0 cá»§a táº¥t cáº£ cÃ¡c worker node, Ä‘Ã¢y chÃ­nh lÃ  lÃ½ do táº¡i sao khÃ´ng thá»ƒ táº¡o nhiá»u Servicce (NodePort) fix cá»©ng nodePort giá»‘ng nhau.

```yaml
---
apiVersion: v1
kind: Service
metadata:
  name: service-test
spec:
  type: NodePort # Virtual IP + map host port
  selector:
    app: service_test_pod # Label selector
  ports:
    - protocol: TCP # Protocol
      port: 80 # Port cá»§a Service
      targetPort: 8080 # Port cá»§a Pod
      nodePort: 30080 # Port cá»§a Host (optional)
```

**LoadBalancer**

![](https://github.com/user-attachments/assets/6716038c-6119-48cf-80f9-af10d28237f6)

LÃºc nÃ y, táº¥t cáº£ cÃ¡c worker node Ä‘á»u listen chung má»™t port duy nháº¥t, client cÃ³ thá»ƒ truy cáº­p vÃ o báº¥t ká»³ node nÃ o trong cá»¥m vá»›i port duy nháº¥t trÃªn Ä‘á»ƒ káº¿t ná»‘i tá»›i Pod bÃªn trong. **_Váº¥n Ä‘á» á»Ÿ Ä‘Ã¢y lÃ  chÃºng ta cung cáº¥p Ä‘á»‹a chá»‰ IP cá»§a worker node nÃ o cho client? nhá»¡ worker node Ä‘Ã³ cháº¿t thÃ¬ sao?_**

VÃ­ dá»¥ Ä‘Æ¡n giáº£n nháº¥t lÃ  trÃªn dá»‹ch vá»¥ Cloud, cÃ¡c worker node náº±m trÃªn dáº£i VPC network mÃ  client tá»« bÃªn ngoÃ i internet khÃ´ng thá»ƒ truy cáº­p vÃ o Ä‘Æ°á»£c. ChÃºng ta pháº£i cáº§n má»™t con Load Balancer (cÃ³ 1 chÃ¢n public IP phÆ¡i ra cho client truy cáº­p) lÃ m nhiá»‡m vá»¥ cÃ¢n báº±ng táº£i tá»›i cÃ¡c worker node bÃªn trong dáº£i VPC network kia. ÄÃ¢y chÃ­nh lÃ  Service resource cÃ³ type lÃ  **LoadBalancer**.

Tuy nhiÃªn loáº¡i nÃ y khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng phá»• biáº¿n trong thá»±c táº¿, nÃ³ cÅ©ng cháº£ khÃ¡c gÃ¬ con cÃ¢n báº±ng táº£i thÃ´ng thÆ°á»ng cáº£ (nginx, haproxy, envoy,â€¦) VÃ¬ váº­y Ä‘á»ƒ giáº£i quyáº¿t váº¥n Ä‘á» trÃªn, Ä‘a sá»‘ thÆ°á»ng chá»n giáº£i phÃ¡p tá»± dá»±ng Load Balancer cho cá»¥m k8s (cÃ³ thá»ƒ cáº¥u hÃ¬nh Ä‘Æ°á»£c nhiá»u thá»© hÆ¡n so vá»›i Service type LoadBalancer cá»§a k8s).

Khi sá»­ dá»¥ng resource nÃ y trÃªn cloud (vÃ­ dá»¥ nhÆ° Google Cloud, AWS, Azure,â€¦) bá»n nÃ³ sáº½ tá»± Ä‘á»™ng gÃ¡n má»™t public IP cho Service â†’ táº¥t nhiÃªn lÃ  nÃ³ sáº½ tÃ­nh phÃ­ trÃªn má»—i public IP táº¡o ra.

```yaml
---
apiVersion: v1
kind: Service
metadata:
  name: service-test
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-backend-protocol: http
    service.beta.kubernetes.io/aws-load-balancer-ssl-ports: "443,8443"
spec:
  type: LoadBalancer # Virtual IP + map host port + create LB
  selector:
    app: service_test_pod # Label selector
  ports:
    - protocol: TCP # Protocol
      port: 80 # Port cá»§a Service
      targetPort: 8080 # Port cá»§a Pod
      nodePort: 30080 # Port cá»§a Host (optional)
```

### Service KHÃ”NG proxy (Headless Service)

![](https://github.com/user-attachments/assets/d34c7ba8-fa75-4447-80ef-3d1e31956b51)

```yaml
---
apiVersion: v1
kind: Service
metadata:
  name: service-test
spec:
  clusterIP: None # KhÃ´ng táº¡o Virtual IP
  selector:
    app: service_test_pod # Label selector
  ports:
    - protocol: TCP # Protocol
      targetPort: 8080 # Port cá»§a Pod
```

- ÄÃ¢y lÃ  loáº¡i Service khÃ´ng sá»­ dá»¥ng proxy - Ä‘á»“ng nghÄ©a vá»›i viá»‡c nÃ³ sáº½ khÃ´ng táº¡o báº¥t ká»³ Virtual IP nÃ o vÃ  client sáº½ káº¿t ná»‘i thÃ´ng qua cÆ¡ cháº¿ **DNS Load Balancing**.

- Thay vÃ¬ tráº£ vá» Virtual IP, khi truy cáº­p vÃ o domain service-test sáº½ Ä‘Æ°á»£c resolve ra danh sÃ¡ch cÃ¡c Ä‘á»‹a chá»‰ IP cá»§a server Pod. PhÃ­a client cáº§n pháº£i chá»n ra Ä‘á»‹a chá»‰ IP cá»§a Pod mÃ  nÃ³ muá»‘n káº¿t ná»‘i Ä‘áº¿n, DNS server cá»§a k8s cÅ©ng há»— trá»£ LB sá»­ dá»¥ng thuáº­t toÃ¡n round robin Ä‘á»ƒ tráº£ vá» danh sÃ¡ch Ä‘á»‹a chá»‰ IP cá»§a cÃ¡c server Pod.

- LÃºc nÃ y client Pod sáº½ khÃ´ng káº¿t ná»‘i tá»›i server Pod thÃ´ng qua Virtual IP cá»§a Service resource ná»¯a, thay vÃ o Ä‘Ã³ nÃ³ sáº½ thá»±c hiá»‡n káº¿t ná»‘i trá»±c tiáº¿p tá»›i 1 Pod server. CÃ¡ch nÃ y chÃºng ta khÃ´ng thá»ƒ mapping port cá»§a container Pod vá»›i má»™t port báº¥t ká»³ nÃ o khÃ¡c, nÃªn cÃ¡c káº¿t ná»‘i cáº§n pháº£i sá»­ dá»¥ng chÃ­nh xÃ¡c port cá»§a container trong Pod.

- NhÆ° vÃ­ dá»¥ á»Ÿ diagram phÃ­a trÃªn, chÃºng ta cÃ³ thá»ƒ truy cáº­p vÃ o server Pod thÃ´ng qua DNS name `service-test:8080` hoáº·c `10.0.1.2:8080`, `10.0.2.2:8080`. NÃ³ váº«n Ä‘áº£m báº£o cÆ¡ cháº¿ healthcheck cÃ¡c server Pod phÃ­a sau vÃ  tráº£ vá» danh sÃ¡ch cÃ¡c Ä‘á»‹a chá»‰ IP cá»§a healthy Pod.

![](https://github.com/user-attachments/assets/fbdf3334-5a5a-4fac-9369-b51ef0dbd3d5)

Má»™t trÆ°á»ng há»£p sá»­ dá»¥ng ná»¯a Ä‘á»‘i vá»›i **Service NO proxy** lÃ  cáº¥u hÃ¬nh káº¿t ná»‘i tá»›i Database server bÃªn ngoÃ i cá»¥m (nhÆ° diagram á»Ÿ trÃªn), chÃºng ta sáº½ thiáº¿t káº¿ Service resource vá»›i clusterIP lÃ  None vÃ  má»™t Manual Endpoint Ä‘á»ƒ cáº¥u hÃ¬nh Ä‘á»‹a chá»‰ IP vÃ  port (cá»§a PostgreSQL server).

Khi táº¡o Service resource, thÃ´ng tin cá»§a Service sáº½ Ä‘Æ°á»£c k8s apiserver cáº­p nháº­t vÃ o DNS server (chÃ­nh lÃ  `core-dns` container trong kube-system namspace). VÃ¬ váº­y trong golang API container cÃ³ thá»ƒ resolve Ä‘Æ°á»£c Ä‘á»‹a chá»‰ IP cá»§a database service lÃ  `192.0.2.42`.

```yaml
---
apiVersion: v1
kind: Service
metadata:
  name: database
spec:
  clusterIP: None
  ports:
    - protocol: TCP
      targetPort: 5432
---
apiVersion: v1
kind: Endpoints
metadata:
  name: database
subsets:
  - addresses:
      - ip: 192.0.2.42
    ports:
      - port: 5432
```

## TÃ¬m hiá»ƒu thÃªm vá» K8s Networking

- Pod network: [TÃ¬m hiá»ƒu vá» Pod network](/posts/kubernetes/learn-about-pod-network/)
- Ingress network: [TÃ¬m hiá»ƒu vá» Ingress network](/posts/kubernetes/learn-about-ingress-network/)

## Reference Link

- Giáº£i thÃ­ch chi tiáº¿t vá» Service network trong k8s: [https://medium.com/google-cloud/understanding-kubernetes-networking-services-f0cb48e4cc82](https://medium.com/google-cloud/understanding-kubernetes-networking-services-f0cb48e4cc82)
- So sÃ¡nh sá»± khÃ¡c nhau giá»¯a Service (cÃ³ proxy) vÃ  Headless Service (khÃ´ng proxy): [https://dev.to/kaoskater08/building-a-headless-service-in-kubernetes-3bk8](https://dev.to/kaoskater08/building-a-headless-service-in-kubernetes-3bk8)
- So sÃ¡nh chi tiáº¿t giá»¯a cÃ¡c CNI plugins: [https://rancher.com/blog/2019/2019-03-21-comparing-kubernetes-cni-providers-flannel-calico-canal-and-weave](https://rancher.com/blog/2019/2019-03-21-comparing-kubernetes-cni-providers-flannel-calico-canal-and-weave)
- Xem chi tiáº¿t cÃ¡ch kube-proxy vá»›i netfilter hoáº¡t Ä‘á»™ng nhÆ° nÃ o: [https://www.stackrox.com/post/2020/01/kubernetes-networking-demystified](https://www.stackrox.com/post/2020/01/kubernetes-networking-demystified)
- Xem chi tiáº¿t tÃ i liá»‡u vá» netfilter vÃ  iptables: [https://news.cloud365.vn/chuyen-sau-ve-iptables-command-va-netfilter](https://news.cloud365.vn/chuyen-sau-ve-iptables-command-va-netfilter)
- Xem chi tiáº¿t tÃ i liá»‡u vá» calico plugin [á»Ÿ Ä‘Ã¢y](https://object-storage-ca-ymq-1.vexxhost.net/swift/v1/6e4619c416ff4bd19e1c087f27a43eea/www-assets-prod/presentation-media/k8s-calico-v1.0.pdf)
- PhÃ¢n biá»‡t Port, TargetPort vÃ  NodePort trong Kubernetes á»Ÿ Ä‘Ã¢y: [https://matthewpalmer.net/kubernetes-app-developer/articles/kubernetes-ports-targetport-nodeport-service.html](https://matthewpalmer.net/kubernetes-app-developer/articles/kubernetes-ports-targetport-nodeport-service.html)
